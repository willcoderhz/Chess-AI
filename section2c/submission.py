
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###͏︅͏︀͏︋͏︋͏󠄌͏󠄎͏󠄋͏󠄉͏󠄈͏︁
#################################################
# file to edit: notebook.ipynb͏︅͏︀͏︋͏︋͏󠄌͏󠄎͏󠄋͏󠄉͏󠄈͏︁

import time
from isolation import Board

# Credits if any͏︅͏︀͏︋͏︋͏󠄌͏󠄎͏󠄋͏󠄉͏󠄈͏︁
# 1)͏︅͏︀͏︋͏︋͏󠄌͏󠄎͏󠄋͏󠄉͏󠄈͏︁
# 2)͏︅͏︀͏︋͏︋͏󠄌͏󠄎͏󠄋͏󠄉͏󠄈͏︁
# 3)͏︅͏︀͏︋͏︋͏󠄌͏󠄎͏󠄋͏󠄉͏󠄈͏︁

class OpenMoveEvalFn:
    def score(self, game, my_player=None):
        """Score the current game state
        Evaluation function that outputs a score equal to how many
        moves are open for AI player on the board minus how many moves
        are open for Opponent's player on the board.

        Note:
            If you think of better evaluation function, do it in CustomEvalFn below.

            Args
                game (Board): The board and game state.
                my_player (Player object): This specifies which player you are.

            Returns:
                float: The current state's score. MyMoves-OppMoves.

            """

        # TODO: finish this function!͏︅͏︀͏︋͏︋͏󠄌͏󠄎͏󠄋͏󠄉͏󠄈͏︁


         # Get the number of legal moves for the AI
        my_moves = len(game.get_player_moves(my_player))

        # Get the number of legal moves for the opponent player
        opp_moves = len(game.get_opponent_moves(my_player))

        # Return the difference
        return float(my_moves - opp_moves)





######################################################################
########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︅͏︀͏︋͏︋͏󠄌͏󠄎͏󠄋͏󠄉͏󠄈͏︁
######## IF YOU WANT TO CALL OR TEST IT CREATE A NEW CELL ############͏︅͏︀͏︋͏︋͏󠄌͏󠄎͏󠄋͏󠄉͏󠄈͏︁
######################################################################
##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︅͏︀͏︋͏︋͏󠄌͏󠄎͏󠄋͏󠄉͏󠄈͏︁
################ END OF LOCAL TEST CODE SECTION ######################͏︅͏︀͏︋͏︋͏󠄌͏󠄎͏󠄋͏󠄉͏󠄈͏︁

class CustomPlayer:
    """Player that chooses a move using your evaluation function
    and a minimax algorithm with alpha-beta pruning."""

    def __init__(self, search_depth=7, eval_fn=CustomEvalFn()):
        """Initializes your player.

        Args:
            search_depth (int): The depth to which your agent will search.
            eval_fn (function): Evaluation function used by your agent.
        """
        self.eval_fn = eval_fn  # Using your custom evaluation function
        self.search_depth = search_depth

    def move(self, game, time_left):
        """Called to determine one move by your agent.

        Note:
            1. Do NOT change the name of this 'move' function. We are going to call
            this function directly.
            2. Call alphabeta instead of minimax once implemented.

        Args:
            game (Board): The board and game state.
            time_left (function): Used to determine time left before timeout.

        Returns:
            tuple: (int, int): Your best move.
        """
        # Perform the alphabeta search to find the best move within the given search depth
        best_move, utility = alphabeta(self, game, time_left, depth=self.search_depth)

        # Return the best move found by alphabeta
        return best_move

    def utility(self, game, my_turn):
        """Calculate the utility of the current game state for the agent.

        Args:
            game (Board): The board and game state.
            my_turn (bool): Indicates if it is the agent's turn.

        Returns:
            float: Utility value for the current game state.
        """
        # Use the custom evaluation function to score the current state
        return self.eval_fn.score(game, self)




###################################################################
########## DON'T WRITE ANY CODE OUTSIDE THE CLASS! ################͏︅͏︀͏︋͏︋͏󠄌͏󠄎͏󠄋͏󠄉͏󠄈͏︁
###### IF YOU WANT TO CALL OR TEST IT CREATE A NEW CELL ###########͏︅͏︀͏︋͏︋͏󠄌͏󠄎͏󠄋͏󠄉͏󠄈͏︁
###################################################################


def minimax(player, game, time_left, depth, my_turn=True):
    """Implementation of the minimax algorithm.

    Args:
        player (CustomPlayer): The instance representing the AI player.
        game (Board): The current board and game state.
        time_left (function): A function to check the time remaining before timeout.
        depth (int): How deep you are in the search tree.
        my_turn (bool): True if it's the AI player's turn, False if it's the opponent's turn.

    Returns:
        tuple: (best_move, best_value) where best_move is the best move for the AI, and best_value is the utility of that move.
    """
    # Check if time is almost up
    if time_left() < 10:
        return None, player.utility(game, my_turn)

    # Base case: check if the depth is 0 or if there are no legal moves
    if depth == 0:
        return None, player.utility(game, my_turn)

    # Get the legal moves for the current player or opponent
    if my_turn:
        legal_moves = game.get_player_moves(player)
    else:
        legal_moves = game.get_opponent_moves(player)

    # If no legal moves are available, return the utility score
    if not legal_moves:
        return None, player.utility(game, my_turn)

    # Maximizing player (AI's turn)
    if my_turn:
        best_val = float('-inf')
        best_move = None
        for move in legal_moves:
            # Simulate the move and get the new game state
            forecasted_game = game.forecast_move(move)

            if isinstance(forecasted_game, tuple):
                forecasted_game = forecasted_game[0]

            # Recursively call minimax for the opponent's turn
            _, move_value = minimax(player, forecasted_game, time_left, depth - 1, my_turn=False)

            # Choose the move with the highest value
            if move_value > best_val:
                best_val = move_value
                best_move = move
        return best_move, best_val

    # Minimizing player (opponent's turn)
    else:
        best_val = float('inf')
        best_move = None
        for move in legal_moves:

            forecasted_game = game.forecast_move(move)

            if isinstance(forecasted_game, tuple):
                forecasted_game = forecasted_game[0]

             # Recursively call minimax for the opponent's turn, here is the AI
            _, move_value = minimax(player, forecasted_game, time_left, depth - 1, my_turn=True)

            # Choose the move with the lowest value, because here assuming the opponents would also try the best step
            if move_value < best_val:
                best_val = move_value
                best_move = move
        return best_move, best_val




######################################################################
########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︅͏︀͏︋͏︋͏󠄌͏󠄎͏󠄋͏󠄉͏󠄈͏︁
######## IF YOU WANT TO CALL OR TEST IT CREATE A NEW CELL ############͏︅͏︀͏︋͏︋͏󠄌͏󠄎͏󠄋͏󠄉͏󠄈͏︁
######################################################################
##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︅͏︀͏︋͏︋͏󠄌͏󠄎͏󠄋͏󠄉͏󠄈͏︁
################ END OF LOCAL TEST CODE SECTION ######################͏︅͏︀͏︋͏︋͏󠄌͏󠄎͏󠄋͏󠄉͏󠄈͏︁


def alphabeta(player, game, time_left, depth, alpha=float("-inf"), beta=float("inf"), my_turn=True):
    """Alphabeta implementation with iterative deepening and improved time management."""

    best_move = None
    best_value = float("-inf")  # Start with worst possible value for maximizing player

    # Perform iterative deepening
    for d in range(1, depth + 1):
        # Call depth-limited alphabeta
        move, value = alphabeta_depth_limited(player, game, time_left, d, alpha, beta, my_turn)

        # If time is running out, stop and return the best found move/value so far
        if time_left() < 5:  # Increased the buffer to 50ms
            break

        # If a valid move is found, update the best move and value
        if move is not None:
            best_move = move
            best_value = value

    # Return the best move found and its associated value
    return best_move, best_value


def alphabeta_depth_limited(player, game, time_left, depth, alpha=float("-inf"), beta=float("inf"), my_turn=True):
    """Depth-limited alphabeta search with alpha-beta pruning."""

    # Stop search if time is almost up
    if time_left() < 5:  # Safer buffer
        return None, player.utility(game, my_turn)

    # Base case: If depth is 0 or game is over, return utility score
    if depth == 0:
        return None, player.utility(game, my_turn)

    # Get legal moves based on whose turn it is
    if my_turn:
        legal_moves = game.get_player_moves(player)
    else:
        legal_moves = game.get_opponent_moves(player)

    # If no legal moves are available, return the utility score
    if not legal_moves:
        return None, player.utility(game, my_turn)

    # Maximizing player (AI's turn)
    if my_turn:
        best_val = float('-inf')
        best_move = None
        for move in legal_moves:
            forecasted_game = game.forecast_move(move)
            if isinstance(forecasted_game, tuple):
                forecasted_game = forecasted_game[0]

            # Recursively call alphabeta for the next depth
            _, move_val = alphabeta_depth_limited(player, forecasted_game, time_left, depth - 1, alpha, beta, my_turn=False)

            # Update the best value and move
            if move_val > best_val:
                best_val = move_val
                best_move = move

            # Update alpha and check for beta cutoff
            alpha = max(alpha, best_val)
            if beta <= alpha:
                break  # Beta cutoff (pruning)

        return best_move, best_val

    # Minimizing player (opponent's turn)
    else:
        best_val = float('inf')
        best_move = None
        for move in legal_moves:
            forecasted_game = game.forecast_move(move)
            if isinstance(forecasted_game, tuple):
                forecasted_game = forecasted_game[0]

            # Recursively call alphabeta for the next depth
            _, move_val = alphabeta_depth_limited(player, forecasted_game, time_left, depth - 1, alpha, beta, my_turn=True)

            # Update the best value and move
            if move_val < best_val:
                best_val = move_val
                best_move = move

            # Update beta and check for alpha cutoff
            beta = min(beta, best_val)
            if beta <= alpha:
                break  # Alpha cutoff (pruning)

        return best_move, best_val





######################################################################
########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################
######## IF YOU WANT TO CALL OR TEST IT CREATE A NEW CELL ############
######################################################################
##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######
# Uncomment and modify the following line to run your AlphaBeta test
################ END OF LOCAL TEST CODE SECTION ######################



class CustomEvalFn:
    def __init__(self):
        pass

    def score(self, game, my_player=None):
        """Score the current game state.

        Custom evaluation function to score the game state based on heuristics
        such as mobility (number of moves available) and positional advantage.

        Args:
            game (Board): The board and game state.
            my_player (Player object): This specifies which player you are.

        Returns:
            float: The current state's score, based on your own heuristic.
        """

        # Heuristic 1: Mobility (number of legal moves)
        my_moves = len(game.get_player_moves(my_player))
        opponent_moves = len(game.get_opponent_moves(my_player))
        mobility_score = my_moves - opponent_moves

        # Heuristic 2: Positional advantage (e.g., controlling the center)
        center_position = (game.width // 2, game.height // 2)
        my_position = game.get_player_location(my_player)
        opponent_position = game.get_player_location(game.get_opponent(my_player))

        # Distance to the center of the board for both players
        my_distance_to_center = euclidean_distance(my_position, center_position)
        opponent_distance_to_center = euclidean_distance(opponent_position, center_position)

        # Encourage being closer to the center
        positional_score = opponent_distance_to_center - my_distance_to_center

        # Combine the two heuristics (mobility and positional advantage)
        total_score = (2 * mobility_score) + positional_score

        return float(total_score)


def euclidean_distance(pos1, pos2):
    """Calculate the Euclidean distance between two positions."""
    return ((pos1[0] - pos2[0]) ** 2 + (pos1[1] - pos2[1]) ** 2) ** 0.5



######################################################################
############ DON'T WRITE ANY CODE OUTSIDE THE CLASS! #################͏︅͏︀͏︋͏︋͏󠄌͏󠄎͏󠄋͏󠄉͏󠄈͏︁
######## IF YOU WANT TO CALL OR TEST IT CREATE A NEW CELL ############͏︅͏︀͏︋͏︋͏󠄌͏󠄎͏󠄋͏󠄉͏󠄈͏︁
######################################################################